{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embedding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWSjsJiD9Qk1tjmsC0jnet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vyoma-garg/Natural-Language-Processing/blob/main/Word_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikUZ6JpBhRZO"
      },
      "source": [
        "## **Word Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkcV3ynlrlg0"
      },
      "source": [
        "**Taking 200 Documents for creating corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igfYAqzCrbyq",
        "outputId": "6bd783d8-2a7c-44d1-a81b-5446f4b8c3c7"
      },
      "source": [
        "corpus=newsgroups_train.data[0:200]\n",
        "type(corpus)\n",
        "#corpus[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgjmS5u69nWQ"
      },
      "source": [
        "### **(i)Word2Vec Embedding Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy2xeTxhqw_a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "#X_data, y_data = corpus, bin_sentiment\n",
        "X_data, y_data = np.array(newsgroups_train.target_names), np.array(newsgroups_train.target)\n",
        "print(X_data)\n",
        "print(y_data)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state = 40)\n",
        "print('Data Split done.')\n",
        "X_data.shape\n",
        "y_data.shape\n",
        "\n",
        "y_test.shape\n",
        "type(X_train)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgdLt-aBsYgp",
        "outputId": "da7c9968-a4d4-4602-9a1e-1cc60ad6237c"
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUbmlTzZsaXM",
        "outputId": "f4833c6b-8b69-4218-cd47-73d1fe639582"
      },
      "source": [
        "Embedding_dimensions = 100\n",
        "Word2vec_train_data = list(map(lambda x: x.split(), corpus))\n",
        "len(Word2vec_train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmLmUieLshBD",
        "outputId": "50371ba5-521b-404a-9df0-bba106c64822"
      },
      "source": [
        "# Defining the model and training it.\n",
        "word2vec_model = Word2Vec(Word2vec_train_data ,\n",
        "                 size=Embedding_dimensions,\n",
        "                 workers=8,\n",
        "                 min_count=5)\n",
        "\n",
        "print(\"Vocabulary Length:\", len(word2vec_model.wv.vocab))\n",
        "\n",
        "#word2vec_model.wv.vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Length: 1273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnClU2j9QSC7"
      },
      "source": [
        "input_length = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbai0gJDQSC8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znZAdhGEQSC8",
        "outputId": "c3b26bb9-2e4f-4c79-f393-f7f4ee49b1ae"
      },
      "source": [
        "tokenizer = Tokenizer(filters=\"\", lower=True)\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "vocab_length = len(tokenizer.word_index) + 1\n",
        "print(\"Tokenizer vocab length:\", vocab_length)\n",
        "lili=list(tokenizer.word_index)\n",
        "#lili"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizer vocab length: 16590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vqpk9GTQSC9"
      },
      "source": [
        "tokenizer.word_index.items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGToZVFDQK9U"
      },
      "source": [
        "**WORD2VEC EMBEDDING MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbz1TV8pQSC-",
        "outputId": "84f5cf6b-af9a-45c3-a223-4fcd2c59c80e"
      },
      "source": [
        "import numpy as np\n",
        "embedding_matrix = np.zeros((vocab_length, Embedding_dimensions))\n",
        "\n",
        "for word, token in tokenizer.word_index.items():\n",
        "    if word2vec_model.wv.__contains__(word):\n",
        "        embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n",
        "\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)\n",
        "embedding_matrix\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding Matrix Shape: (16590, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.09553948,  0.42800477,  1.15113389, ..., -0.55253488,\n",
              "        -0.04539686,  0.2248902 ],\n",
              "       [ 0.10282847,  0.41432583,  1.12297511, ..., -0.5347597 ,\n",
              "        -0.05884048,  0.21773049],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFXZw8llQSC-"
      },
      "source": [
        "### **(ii)GLOVE embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KQXWIsXQSC-",
        "outputId": "de1e850e-80c0-4906-ff70-1757fa8bc9ea"
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-04 10:40:50--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-05-04 10:40:51--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.04MB/s    in 2m 40s  \n",
            "\n",
            "2021-05-04 10:43:31 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBliD22mQSC-",
        "outputId": "92699eb0-61d9-4ccf-dc11-56d314181559"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQO0pmdpQSC_"
      },
      "source": [
        "embeddings_index = dict()\n",
        "\n",
        "f = open('/content/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhKRTInBQVCe"
      },
      "source": [
        "**GLOVE EMBEDDING MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD1h5jvQQSC_",
        "outputId": "df55661f-d499-40b9-f848-c688e228b66a"
      },
      "source": [
        "embedding_matrix_glove = np.zeros((vocab_length,100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_glove[i] = embedding_vector\n",
        "print(embedding_matrix_glove.shape)\n",
        "embedding_matrix_glove\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16590, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
              "         0.82779998,  0.27061999],\n",
              "       [-0.1529    , -0.24279   ,  0.89837003, ..., -0.59100002,\n",
              "         1.00390005,  0.20664001],\n",
              "       ...,\n",
              "       [-0.12134   ,  0.25116   , -0.28042001, ...,  0.44575   ,\n",
              "        -0.10716   , -0.68197   ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uag6gpTw_L0T"
      },
      "source": [
        "### **(iii)Fasttext Word Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo3nQ2PYLIGw"
      },
      "source": [
        "# Defining values for parameters\n",
        "embedding_size = 100\n",
        "window_size = 5\n",
        "min_word = 5\n",
        "down_sampling = 1e-2\n",
        " \n",
        "#%%time\n",
        "fast_Text_model = FastText(Word2vec_train_data,\n",
        "                      size=embedding_size,\n",
        "                      window=window_size,\n",
        "                      min_count=min_word,\n",
        "                      sample=down_sampling,\n",
        "                      workers = 4,\n",
        "                      sg=1,\n",
        "                      iter=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qf1aaZjQh68"
      },
      "source": [
        "**FASTTEXT EMBEDDING MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XEBO5U4LaFi",
        "outputId": "dd75cb11-6a0b-489f-d680-1e08fc5fb968"
      },
      "source": [
        "import numpy as np\n",
        "embedding_matrix_fasttext = np.zeros((vocab_length, Embedding_dimensions))\n",
        "\n",
        "for word, token in tokenizer.word_index.items():\n",
        "    if fast_Text_model.wv.__contains__(word):\n",
        "       embedding_matrix_fasttext [token] = fast_Text_model.wv.__getitem__(word)\n",
        "\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix_fasttext .shape)\n",
        "embedding_matrix_fasttext \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding Matrix Shape: (16590, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.13058279,  0.30853915,  0.06052507, ..., -0.10447433,\n",
              "         0.42034531,  0.22874126],\n",
              "       [ 0.23419413,  0.05552264,  0.3274363 , ..., -0.32826954,\n",
              "         0.34291354,  0.07401072],\n",
              "       ...,\n",
              "       [ 0.19601822,  0.55284888,  0.80247927, ..., -0.47504708,\n",
              "         0.90072495,  0.13029887],\n",
              "       [ 0.19215195,  0.01958453,  0.74994725, ...,  0.38403332,\n",
              "        -0.06862366,  0.46224916],\n",
              "       [ 0.09854463,  0.13877454,  0.98170364, ...,  0.13627307,\n",
              "        -0.17717718,  0.43741387]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    }
  ]
}