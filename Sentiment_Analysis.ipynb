{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP15FKidTwmYZyioqeiC5iC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vyoma-garg/Natural-Language-Processing/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBcnvyrr0_Y7"
      },
      "source": [
        "## **Getting dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnMHXG6gfYhc"
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "false=False\n",
        "true=True\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open('/content/Magazine_Subscriptions.json.gz', 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('Magazine_Subscriptions.json.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP8d00Zf4u8H"
      },
      "source": [
        "Total Number of Magazine Subscriptions reviews "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW_vMI43puBl",
        "outputId": "99f33685-1fc4-4f41-cc6c-6e462e19d091"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89689"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJlNnM_q41bn"
      },
      "source": [
        "Total Number of reviews taken in consideration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYte2g0s6zT4",
        "outputId": "43eec265-7662-4769-eca4-5e810836c25b"
      },
      "source": [
        "df=df[:25000]\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpUu6Uz6vBN",
        "outputId": "30ead3cf-c609-4d97-cc4c-dfd8214bd1bd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>vote</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>11 8, 2001</td>\n",
              "      <td>AH2IFH762VY5U</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>ted sedlmayr</td>\n",
              "      <td>for computer enthusiast, MaxPC is a welcome si...</td>\n",
              "      <td>AVID READER SINCE \"boot\"  WAS THE NAME</td>\n",
              "      <td>1005177600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>10 31, 2001</td>\n",
              "      <td>AOSFI0JEYU4XM</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>Thank god this is not a Ziff Davis publication...</td>\n",
              "      <td>The straight scoop</td>\n",
              "      <td>1004486400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>03 24, 2007</td>\n",
              "      <td>A3JPFWKS83R49V</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Bryan Carey</td>\n",
              "      <td>Antiques Magazine is a publication made for an...</td>\n",
              "      <td>Antiques Magazine is Good, but not for Everyone</td>\n",
              "      <td>1174694400</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>11 10, 2006</td>\n",
              "      <td>A19FKU6JZQ2ECJ</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Patricia L. Porada</td>\n",
              "      <td>This beautiful magazine is in itself a work of...</td>\n",
              "      <td>THE  DISCERNING READER</td>\n",
              "      <td>1163116800</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>07 14, 2014</td>\n",
              "      <td>A25MDGOMZ2GALN</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Alvey</td>\n",
              "      <td>A great read every issue.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1405296000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall vote  verified  ... unixReviewTime                           style image\n",
              "0      5.0    9     False  ...     1005177600                             NaN   NaN\n",
              "1      5.0    9     False  ...     1004486400                             NaN   NaN\n",
              "2      3.0   14     False  ...     1174694400  {'Format:': ' Print Magazine'}   NaN\n",
              "3      5.0   13     False  ...     1163116800  {'Format:': ' Print Magazine'}   NaN\n",
              "4      5.0  NaN      True  ...     1405296000                             NaN   NaN\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7kB2-UM5AKy"
      },
      "source": [
        "Adding a column for Positive and Negative Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxKyzr1wpxb8",
        "outputId": "f4ebbc14-edb9-41ed-d3c6-9d6a302e1fe7"
      },
      "source": [
        "df.loc[df['overall']<=3, 'Sentiment']='Negative'\n",
        "df.loc[df['overall']>3, 'Sentiment']='Positive'\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>vote</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>11 8, 2001</td>\n",
              "      <td>AH2IFH762VY5U</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>ted sedlmayr</td>\n",
              "      <td>for computer enthusiast, MaxPC is a welcome si...</td>\n",
              "      <td>AVID READER SINCE \"boot\"  WAS THE NAME</td>\n",
              "      <td>1005177600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>10 31, 2001</td>\n",
              "      <td>AOSFI0JEYU4XM</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>Thank god this is not a Ziff Davis publication...</td>\n",
              "      <td>The straight scoop</td>\n",
              "      <td>1004486400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>03 24, 2007</td>\n",
              "      <td>A3JPFWKS83R49V</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Bryan Carey</td>\n",
              "      <td>Antiques Magazine is a publication made for an...</td>\n",
              "      <td>Antiques Magazine is Good, but not for Everyone</td>\n",
              "      <td>1174694400</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>11 10, 2006</td>\n",
              "      <td>A19FKU6JZQ2ECJ</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Patricia L. Porada</td>\n",
              "      <td>This beautiful magazine is in itself a work of...</td>\n",
              "      <td>THE  DISCERNING READER</td>\n",
              "      <td>1163116800</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>07 14, 2014</td>\n",
              "      <td>A25MDGOMZ2GALN</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Alvey</td>\n",
              "      <td>A great read every issue.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1405296000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall vote  verified  ...                           style image Sentiment\n",
              "0      5.0    9     False  ...                             NaN   NaN  Positive\n",
              "1      5.0    9     False  ...                             NaN   NaN  Positive\n",
              "2      3.0   14     False  ...  {'Format:': ' Print Magazine'}   NaN  Negative\n",
              "3      5.0   13     False  ...  {'Format:': ' Print Magazine'}   NaN  Positive\n",
              "4      5.0  NaN      True  ...                             NaN   NaN  Positive\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmKpOKd15KHA"
      },
      "source": [
        "Adding a column for Sentiments in binary form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgYhVeC9jSlq",
        "outputId": "e63eda4f-1ed0-4cf0-9fe6-e927ac38daa4"
      },
      "source": [
        "df.loc[df['Sentiment']=='Negative', 'Binary_Sentiment']=0\n",
        "df.loc[df['Sentiment']=='Positive', 'Binary_Sentiment']=1\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>vote</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Binary_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>11 8, 2001</td>\n",
              "      <td>AH2IFH762VY5U</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>ted sedlmayr</td>\n",
              "      <td>for computer enthusiast, MaxPC is a welcome si...</td>\n",
              "      <td>AVID READER SINCE \"boot\"  WAS THE NAME</td>\n",
              "      <td>1005177600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>False</td>\n",
              "      <td>10 31, 2001</td>\n",
              "      <td>AOSFI0JEYU4XM</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>Thank god this is not a Ziff Davis publication...</td>\n",
              "      <td>The straight scoop</td>\n",
              "      <td>1004486400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>03 24, 2007</td>\n",
              "      <td>A3JPFWKS83R49V</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Bryan Carey</td>\n",
              "      <td>Antiques Magazine is a publication made for an...</td>\n",
              "      <td>Antiques Magazine is Good, but not for Everyone</td>\n",
              "      <td>1174694400</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Negative</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>13</td>\n",
              "      <td>False</td>\n",
              "      <td>11 10, 2006</td>\n",
              "      <td>A19FKU6JZQ2ECJ</td>\n",
              "      <td>B00005N7OJ</td>\n",
              "      <td>Patricia L. Porada</td>\n",
              "      <td>This beautiful magazine is in itself a work of...</td>\n",
              "      <td>THE  DISCERNING READER</td>\n",
              "      <td>1163116800</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>07 14, 2014</td>\n",
              "      <td>A25MDGOMZ2GALN</td>\n",
              "      <td>B00005N7P0</td>\n",
              "      <td>Alvey</td>\n",
              "      <td>A great read every issue.</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>1405296000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall vote  verified  ... image Sentiment Binary_Sentiment\n",
              "0      5.0    9     False  ...   NaN  Positive              1.0\n",
              "1      5.0    9     False  ...   NaN  Positive              1.0\n",
              "2      3.0   14     False  ...   NaN  Negative              0.0\n",
              "3      5.0   13     False  ...   NaN  Positive              1.0\n",
              "4      5.0  NaN      True  ...   NaN  Positive              1.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-cIGrHXBzsH",
        "outputId": "fa51f8fa-d136-4e76-a022-a084a4102d16"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>vote</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Binary_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>03 24, 2015</td>\n",
              "      <td>A1AG7VJ1T35X77</td>\n",
              "      <td>B00005QJE0</td>\n",
              "      <td>Darrin R. West</td>\n",
              "      <td>Gorgeous large format magazine. Very inspiring...</td>\n",
              "      <td>Gorgeous and Inspiring.</td>\n",
              "      <td>1427155200</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>07 30, 2014</td>\n",
              "      <td>A365DG6L5EUQQB</td>\n",
              "      <td>B00005QJE0</td>\n",
              "      <td>Charles Belew</td>\n",
              "      <td>Very happy with our subscribtions!</td>\n",
              "      <td>Four Stars</td>\n",
              "      <td>1406678400</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>02 26, 2014</td>\n",
              "      <td>A312FAW297PIOZ</td>\n",
              "      <td>B00005QJE0</td>\n",
              "      <td>kwilson</td>\n",
              "      <td>Love advice on gardening and the different gar...</td>\n",
              "      <td>Would. recommend this magazine to everyone .</td>\n",
              "      <td>1393372800</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>04 4, 2013</td>\n",
              "      <td>AUHOX5LLRIF11</td>\n",
              "      <td>B00005QJE0</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>photos are so good I look at these mags over a...</td>\n",
              "      <td>best gardening magazine</td>\n",
              "      <td>1365033600</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>02 6, 2013</td>\n",
              "      <td>A2P4CPM9S3QBDU</td>\n",
              "      <td>B00005QJE0</td>\n",
              "      <td>Linda W Owen</td>\n",
              "      <td>The English Garden is a wonderful gardening ma...</td>\n",
              "      <td>The English Garden, good magizine for Americans</td>\n",
              "      <td>1360108800</td>\n",
              "      <td>{'Format:': ' Print Magazine'}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       overall vote  verified  ... image Sentiment Binary_Sentiment\n",
              "24995      5.0  NaN      True  ...   NaN  Positive              1.0\n",
              "24996      4.0  NaN      True  ...   NaN  Positive              1.0\n",
              "24997      5.0  NaN      True  ...   NaN  Positive              1.0\n",
              "24998      5.0  NaN      True  ...   NaN  Positive              1.0\n",
              "24999      5.0    4      True  ...   NaN  Positive              1.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhvkslIv0vjc"
      },
      "source": [
        "## **Getting the corpus and binary sentiments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlZU1plg9Yyi",
        "outputId": "ce8feb8f-3821-41ec-fd33-d73cf092ddfb"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopset=set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6GH4osYlupe"
      },
      "source": [
        "corpus = df[\"reviewText\"].fillna(' ').values.tolist()\n",
        "rating=df['overall'].values.tolist()\n",
        "sentiment=df['Sentiment'].values.tolist()\n",
        "bin_sentiment=df['Binary_Sentiment'].values.tolist()\n",
        "print(bin_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjrYHbm9cbRQ"
      },
      "source": [
        "## **WORD EMBEDDINGS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUXUqG7H7Tyk"
      },
      "source": [
        "### **(A) TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwj90RIm7TBH",
        "outputId": "d40aeba0-ec87-41db-ebab-052c83b611db"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#create transform\n",
        "vectorizer2=TfidfVectorizer(use_idf=True, lowercase=True, stop_words=stopset)\n",
        "\n",
        "#tokenize and build vocab\n",
        "X_tfidf=vectorizer2.fit_transform(corpus) \n",
        "print(X_tfidf.shape)\n",
        "\n",
        "#printing idf values\n",
        "print(vectorizer2.idf_)\n",
        "\n",
        "df5 = pd.DataFrame(X_tfidf[0].T.todense(), index=vectorizer2.get_feature_names(), columns=[\"TF-IDF\"])\n",
        "df5 = df5.sort_values('TF-IDF', ascending=False)\n",
        "print (df5.head(25))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 25711)\n",
            "[ 6.0768151   6.85000498 10.43352392 ... 10.43352392 10.43352392\n",
            " 10.43352392]\n",
            "               TF-IDF\n",
            "maxpc        0.373384\n",
            "boot         0.236606\n",
            "computing    0.222767\n",
            "enthusiast   0.208770\n",
            "cd           0.190191\n",
            "obcessed     0.145426\n",
            "divx         0.145426\n",
            "savorying    0.145426\n",
            "codecs       0.145426\n",
            "encoding     0.139774\n",
            "merge        0.135764\n",
            "icing        0.132654\n",
            "broadband    0.130113\n",
            "rom          0.126103\n",
            "blessed      0.124461\n",
            "utilities    0.122993\n",
            "formerly     0.121664\n",
            "connections  0.120452\n",
            "bang         0.119336\n",
            "audio        0.118303\n",
            "cake         0.116442\n",
            "sight        0.112651\n",
            "profit       0.109149\n",
            "welcome      0.109149\n",
            "buck         0.107223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V7D1oqdQXzl"
      },
      "source": [
        "### **(B) Word2Vec**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVJQooyUGxWv"
      },
      "source": [
        "Getting the training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezqEoHE4PhwX",
        "outputId": "f65f720d-3fea-4eaf-cc13-97c6743cb92c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "#X_data, y_data = corpus, bin_sentiment\n",
        "X_data, y_data = np.array(corpus), np.array(bin_sentiment)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state = 40)\n",
        "print('Data Split done.')\n",
        "X_data.shape\n",
        "y_data.shape\n",
        "\n",
        "y_test.shape\n",
        "type(X_train)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Split done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18750,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLxcfYTBwEKP",
        "outputId": "ce81541c-c9e3-400b-fbcf-67a36445a12d"
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do65XaX5Qh8a",
        "outputId": "75528282-7ea8-4ac7-a686-a9847955c263"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "Embedding_dimensions = 100\n",
        "\n",
        "# Creating Word2Vec training dataset.\n",
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))\n",
        "len(Word2vec_train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18750"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXGPnAPTQ-wn",
        "outputId": "5bc7f1b7-c948-46ec-fb99-32ba91c1f255"
      },
      "source": [
        "# Defining the model and training it.\n",
        "word2vec_model = Word2Vec(Word2vec_train_data,\n",
        "                 size=Embedding_dimensions,\n",
        "                 workers=8,\n",
        "                 min_count=5)\n",
        "\n",
        "print(\"Vocabulary Length:\", len(word2vec_model.wv.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Length: 9640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i28xde9ZYI4O"
      },
      "source": [
        "input_length = 60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WWI-TXqR07s"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7E5pBX3wv59",
        "outputId": "60d4aa02-d0cb-441e-9cdb-78d87b9af3fb"
      },
      "source": [
        "tokenizer = Tokenizer(filters=\"\", lower=True)\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "vocab_length = len(tokenizer.word_index) + 1\n",
        "print(\"Tokenizer vocab length:\", vocab_length)\n",
        "lili=list(tokenizer.word_index)\n",
        "#lili\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizer vocab length: 64615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkOcQIN-gwOu"
      },
      "source": [
        "tokenizer.word_index.items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcQcEMuQDAxn"
      },
      "source": [
        "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=input_length)\n",
        "X_test1  = pad_sequences(tokenizer.texts_to_sequences(X_test) , maxlen=input_length)\n",
        "\n",
        "print(\"X_train.shape:\", X_train.shape)\n",
        "print(\"X_test.shape :\", X_test1.shape)\n",
        "X_test1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEU1oBzCG__3"
      },
      "source": [
        "WORD2VEC EMBEDDING MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFHfHDEAxKur"
      },
      "source": [
        "import numpy as np\n",
        "embedding_matrix = np.zeros((vocab_length, Embedding_dimensions))\n",
        "\n",
        "for word, token in tokenizer.word_index.items():\n",
        "    if word2vec_model.wv.__contains__(word):\n",
        "        embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n",
        "\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)\n",
        "embedding_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xoRhivf7Htu"
      },
      "source": [
        "### **(C) GLOVE embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J97c18GqAvE3",
        "outputId": "950f1bc1-5fdb-4954-91ca-42a20e94300d"
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-02 07:38:15--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-05-02 07:38:15--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.29MB/s    in 2m 40s  \n",
            "\n",
            "utime(glove.6B.zip): No such file or directory\n",
            "2021-05-02 07:40:56 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ihkzZOkBBg8",
        "outputId": "9117a4c9-52c5-4ebc-f294-dc2a666d74f8"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open glove*.zip, glove*.zip.zip or glove*.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IhXRuZC7R5t"
      },
      "source": [
        "embeddings_index = dict()\n",
        "\n",
        "f = open('/content/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjNDoS78HFdG"
      },
      "source": [
        "GLOVE EMBEDDING MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nsLxdCnCJDY"
      },
      "source": [
        "embedding_matrix_glove = np.zeros((vocab_length,100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_glove[i] = embedding_vector\n",
        "embedding_matrix_glove.shape\n",
        "embedding_matrix_glove\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZaFbyWREoZi"
      },
      "source": [
        "## **Sentiment Analysis Using following models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8pnHv1iK5Sp"
      },
      "source": [
        "## **Q3 (a)BiLSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV1DA4LK4pMM"
      },
      "source": [
        "### **(i)BiLSTM Using Word2Vec embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCejZ0UqxkWc"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Dense, LSTM, Conv1D, Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5YBaNeUxkiO"
      },
      "source": [
        "def getModel():\n",
        "    embedding_layer = Embedding(input_dim = vocab_length, \n",
        "                                output_dim = Embedding_dimensions,\n",
        "                                weights=[embedding_matrix], \n",
        "                                input_length=input_length,\n",
        "                                trainable=False)\n",
        "\n",
        "    model = Sequential([\n",
        "        embedding_layer,\n",
        "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
        "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
        "        Conv1D(100, 5, activation='relu'),\n",
        "        GlobalMaxPool1D(),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid'), cat [0.1,01]\n",
        "                                   f      dog [0.2]\n",
        "    ],\n",
        "    name=\"Sentiment_Model\")\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ria3nfirxuyW",
        "outputId": "18b5ca00-6dba-4266-a26d-dd733a405bba"
      },
      "source": [
        "training_model = getModel()\n",
        "training_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Sentiment_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 100)           6461500   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 60, 200)           160800    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 60, 200)           240800    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 56, 100)           100100    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                1616      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 6,964,833\n",
            "Trainable params: 503,333\n",
            "Non-trainable params: 6,461,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r951zbnywjG"
      },
      "source": [
        "training_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58iuiEumzMnB",
        "outputId": "838fc226-2f81-4985-e764-0804c2656708"
      },
      "source": [
        "history = training_model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=5,\n",
        "    validation_split=0.1,\n",
        "    #callbacks=callbacks,\n",
        "    #verbose=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "17/17 [==============================] - 108s 6s/step - loss: 0.5729 - accuracy: 0.7086 - val_loss: 0.4083 - val_accuracy: 0.7888\n",
            "Epoch 2/5\n",
            "17/17 [==============================] - 97s 6s/step - loss: 0.4146 - accuracy: 0.7965 - val_loss: 0.3782 - val_accuracy: 0.8149\n",
            "Epoch 3/5\n",
            "17/17 [==============================] - 95s 6s/step - loss: 0.3821 - accuracy: 0.8187 - val_loss: 0.3703 - val_accuracy: 0.8235\n",
            "Epoch 4/5\n",
            "17/17 [==============================] - 96s 6s/step - loss: 0.3660 - accuracy: 0.8308 - val_loss: 0.3596 - val_accuracy: 0.8347\n",
            "Epoch 5/5\n",
            "17/17 [==============================] - 96s 6s/step - loss: 0.3627 - accuracy: 0.8325 - val_loss: 0.3548 - val_accuracy: 0.8379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37iiJhQWHsVJ"
      },
      "source": [
        "Test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwxKRlKhzPTp"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix\n",
        "print(X_test1.shape)     \n",
        "y_pred = training_model.predict(X_test1)\n",
        "y_pred = np.where(y_pred>=0.5, 1, 0)\n",
        "print(y_pred)\n",
        "print(y_pred.shape)   # train : 18750 x60 \\\\\\\\ test : 6250x60\\\\\\\\\\ ypred \n",
        "print(type(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aOmeGM4_WHe"
      },
      "source": [
        "print(y_test)\n",
        "print(y_test.shape)\n",
        "y_test1=y_test.reshape((6250,1))\n",
        "y_test1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bre4O2Y_CLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81d638a-0ef6-46d2-f355-d1b8709b853d"
      },
      "source": [
        "print(accuracy_score(y_test1,y_pred))\n",
        "print(f1_score(y_test1,y_pred))\n",
        "print(confusion_matrix(y_test1,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8368\n",
            "0.886968085106383\n",
            "[[1228  520]\n",
            " [ 500 4002]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5BkkRnC6A44"
      },
      "source": [
        "### **(ii)BiLSTM using Glove Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvqt9gsj5_4G"
      },
      "source": [
        "vocab_length=64615"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3VkPDX6Faop"
      },
      "source": [
        "def getModel():\n",
        "    embedding_layer = Embedding(input_dim = vocab_length, \n",
        "                                output_dim = Embedding_dimensions,\n",
        "                                weights=[embedding_matrix_glove], \n",
        "                                input_length=input_length, #60 \n",
        "                                trainable=False)\n",
        "\n",
        "    model = Sequential([\n",
        "        embedding_layer,\n",
        "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
        "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
        "        Conv1D(100, 5, activation='relu'),\n",
        "        GlobalMaxPool1D(),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid'),\n",
        "    ],\n",
        "    name=\"Sentiment_Model\")\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIvRYErDFaow",
        "outputId": "7ca1b66f-cd67-4166-e8e5-eb5868fe87e1"
      },
      "source": [
        "training_model = getModel()\n",
        "training_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Sentiment_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 100)           6461500   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 60, 200)           160800    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 60, 200)           240800    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 56, 100)           100100    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                1616      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 6,964,833\n",
            "Trainable params: 503,333\n",
            "Non-trainable params: 6,461,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m97Qm8uuFaox"
      },
      "source": [
        "training_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inwwE5c-Faox",
        "outputId": "37e0c56a-83f2-4b87-bf53-3a4481cebc10"
      },
      "source": [
        "history = training_model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=1024,\n",
        "    epochs=5,\n",
        "    validation_split=0.1,\n",
        "    #callbacks=callbacks,\n",
        "    #verbose=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "17/17 [==============================] - 102s 5s/step - loss: 0.6216 - accuracy: 0.6628 - val_loss: 0.4881 - val_accuracy: 0.7648\n",
            "Epoch 2/5\n",
            "17/17 [==============================] - 92s 5s/step - loss: 0.4861 - accuracy: 0.7573 - val_loss: 0.4276 - val_accuracy: 0.7888\n",
            "Epoch 3/5\n",
            "17/17 [==============================] - 91s 5s/step - loss: 0.4244 - accuracy: 0.7968 - val_loss: 0.4036 - val_accuracy: 0.8080\n",
            "Epoch 4/5\n",
            "17/17 [==============================] - 91s 5s/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.3982 - val_accuracy: 0.8101\n",
            "Epoch 5/5\n",
            "17/17 [==============================] - 91s 5s/step - loss: 0.3993 - accuracy: 0.8101 - val_loss: 0.3864 - val_accuracy: 0.8245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj74GuYmH81I"
      },
      "source": [
        "Test Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJvFFgGpITN8"
      },
      "source": [
        "#X_data, y_data = corpus, bin_sentiment\n",
        "X_data, y_data = np.array(corpus), np.array(bin_sentiment)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state = 40)\n",
        "print('Data Split done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBmWrm1fFaoz"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix\n",
        "print(X_test1.shape)     \n",
        "y_pred = training_model.predict(X_test1)\n",
        "y_pred = np.where(y_pred>=0.5, 1, 0)\n",
        "print(y_pred)\n",
        "print(y_pred.shape)   # train : 18750 x60 \\\\\\\\ test : 6250x60\\\\\\\\\\ ypred \n",
        "print(type(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4sVIHYdFao0"
      },
      "source": [
        "print(y_test)\n",
        "print(y_test.shape)\n",
        "y_test1=y_test.reshape((6250,1))\n",
        "y_test1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KPZMNEUFao1",
        "outputId": "c622cf64-2388-4b15-8e99-aa4cdf74b3c3"
      },
      "source": [
        "print(accuracy_score(y_test1,y_pred))\n",
        "print(f1_score(y_test1,y_pred))\n",
        "print(confusion_matrix(y_test1,y_pred)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.82592\n",
            "0.8799646954986762\n",
            "[[1174  574]\n",
            " [ 514 3988]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz11_hZlph5i"
      },
      "source": [
        "## **Q3(b) BERT based Sentiment analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uhx38Cy6mrb"
      },
      "source": [
        "df11=df[['reviewText','Binary_Sentiment']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "krUmHO1V7ohY",
        "outputId": "2c28dd1a-6354-4273-c433-446c8bbe9c61"
      },
      "source": [
        "\n",
        "# Dropping the columns having NaN/NaT values\n",
        "df12= df11.dropna()\n",
        "  \n",
        "# Resetting the indices using df.reset_index()\n",
        "df12 = df12.reset_index(drop=True)\n",
        "  \n",
        "df12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>Binary_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>for computer enthusiast, MaxPC is a welcome si...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thank god this is not a Ziff Davis publication...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Antiques Magazine is a publication made for an...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This beautiful magazine is in itself a work of...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A great read every issue.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24986</th>\n",
              "      <td>Gorgeous large format magazine. Very inspiring...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24987</th>\n",
              "      <td>Very happy with our subscribtions!</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24988</th>\n",
              "      <td>Love advice on gardening and the different gar...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24989</th>\n",
              "      <td>photos are so good I look at these mags over a...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24990</th>\n",
              "      <td>The English Garden is a wonderful gardening ma...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24991 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              reviewText  Binary_Sentiment\n",
              "0      for computer enthusiast, MaxPC is a welcome si...               1.0\n",
              "1      Thank god this is not a Ziff Davis publication...               1.0\n",
              "2      Antiques Magazine is a publication made for an...               0.0\n",
              "3      This beautiful magazine is in itself a work of...               1.0\n",
              "4                              A great read every issue.               1.0\n",
              "...                                                  ...               ...\n",
              "24986  Gorgeous large format magazine. Very inspiring...               1.0\n",
              "24987                 Very happy with our subscribtions!               1.0\n",
              "24988  Love advice on gardening and the different gar...               1.0\n",
              "24989  photos are so good I look at these mags over a...               1.0\n",
              "24990  The English Garden is a wonderful gardening ma...               1.0\n",
              "\n",
              "[24991 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJS_iMMJmipL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,test= train_test_split(df12,test_size=0.2,random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYpzXOUkmipL",
        "outputId": "e5f8b8b5-6079-4214-f73f-c0e55a7fb384"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.3MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 33.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356,
          "referenced_widgets": [
            "f6a066db183644e692284ae9ee025f02",
            "1a9389be0996419aad0e37a20b5b5925",
            "7c72cf52614c41e7a6defdb3d3318abd",
            "3a421b47d9cc4059baad15fe3718e0e6",
            "2891ac5ef21c4338968511ddacfb9749",
            "ee594f4e1e374660b81431027f7aa5d0",
            "b76e5e7a08594c51a550b673a7f60574",
            "ce633284ad864ba2abbec0ec93818c13",
            "58ceb754f79c4e26a7f2107f5879914b",
            "e956d589bbca4ee4858ca350f3475fb8",
            "61682631e4a14dd3aaf951f19a51be46",
            "39a42c468e114b54968b963685fc9f99",
            "9852aa2667e84051b83b59d27f1cc038",
            "2336e8b141254b3d9b354136e35654e5",
            "5fc97cb873984c9cb6b89d077411a7e8",
            "db126e1178bb4eaa81e97e1606e8c45b",
            "67313ba350e840f9bbbf42382feaed2a",
            "64e653fd4c3c44c89fc1d2c00323bc97",
            "9ee526c674e64e11b7702c9eeef0e949",
            "37113f1de70a471abe7fe7f3716ff1a0",
            "a12837439e084ed2b547ce219436081b",
            "271a737c87c64e1397db60d07b4629d5",
            "fc603c6a791145658181b659371686f7",
            "045a5e94cbea4185a48633e4ff33fafd",
            "c1d19aaeeb9546e3ae65c56e1ee7691c",
            "96aaf47745a94479b8a0bca25b5d23e9",
            "91ef7c2209f2444aa080d09fa468f6aa",
            "e1377e43534f4f44baac4455235148e2",
            "1e2db170726e4ba4b1bccb133e9e7ff5",
            "355dcdb185de43dc8502d27eb9d07bda",
            "a9b842dbc3ad4055a61332d17b30fe1c",
            "3aec148e5d1c4b469873a50c4100af3b",
            "778a6c3856834e608555f6cd7351c02e",
            "c8e33e397e9843ca97d8978c9e9a555c",
            "4d1dbb9ce948456c9a606dd05a9f11de",
            "dd436bd8c5f340ce87ea5a22c48841c8",
            "0bd9470347a24dc3be611ad2aae8eb61",
            "b1839f1d0dbf45c6bbfd5c2d36621b4a",
            "edafba075b9d45bb87f5561a7b956a8a",
            "8c717f72e3324b21afc375608d2db8c5"
          ]
        },
        "id": "S4h9vlOCmipM",
        "outputId": "08c91447-f522-4ca8-daa7-e7a0a0aa5bfc"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6a066db183644e692284ae9ee025f02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58ceb754f79c4e26a7f2107f5879914b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67313ba350e840f9bbbf42382feaed2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1d19aaeeb9546e3ae65c56e1ee7691c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "778a6c3856834e608555f6cd7351c02e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zspc2ycq8Ebr",
        "outputId": "088239da-ea1f-4b0b-dec6-b05aa78b999d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg9D05CqmipM"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEP3ZC5-mipN"
      },
      "source": [
        "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
        "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[DATA_COLUMN], \n",
        "                                                          text_b = None,\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[DATA_COLUMN], \n",
        "                                                          text_b = None,\n",
        "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
        "  \n",
        "  return train_InputExamples, validation_InputExamples\n",
        "\n",
        "  train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
        "                                                                           test, \n",
        "                                                                           'DATA_COLUMN', \n",
        "                                                                           'LABEL_COLUMN')\n",
        "    \n",
        "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
        "    features = [] # -> will hold InputFeatures to be converted later\n",
        "\n",
        "    for e in examples:\n",
        "        # Documentation is really strong for this method, so please take a look at it\n",
        "        input_dict = tokenizer.encode_plus(\n",
        "            e.text_a,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length, # truncates if len(s) > max_length\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask=True,\n",
        "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
        "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(\n",
        "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def gen():\n",
        "        for f in features:\n",
        "            yield (\n",
        "                {\n",
        "                    \"input_ids\": f.input_ids,\n",
        "                    \"attention_mask\": f.attention_mask,\n",
        "                    \"token_type_ids\": f.token_type_ids,\n",
        "                },\n",
        "                f.label,\n",
        "            )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "        (\n",
        "            {\n",
        "                \"input_ids\": tf.TensorShape([None]),\n",
        "                \"attention_mask\": tf.TensorShape([None]),\n",
        "                \"token_type_ids\": tf.TensorShape([None]),\n",
        "            },\n",
        "            tf.TensorShape([]),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "DATA_COLUMN = 'reviewText'\n",
        "LABEL_COLUMN = 'Binary_Sentiment'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj6mV-hpmipN",
        "outputId": "675e0208-038f-4feb-a613-0495d8c0d9ec"
      },
      "source": [
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
        "\n",
        "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
        "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
        "\n",
        "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
        "validation_data = validation_data.batch(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WfymPR6mipN",
        "outputId": "bf2e2983-94d1-4972-c55f-bac615a1ccf1"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "\n",
        "model.fit(train_data, epochs=2, validation_data=validation_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5644eb3de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f5644eb3de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f566075fd40> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f566075fd40> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "   1250/Unknown - 1878s 1s/step - loss: 0.2658 - accuracy: 0.8890WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1250/1250 [==============================] - 1959s 2s/step - loss: 0.2658 - accuracy: 0.8891 - val_loss: 0.2511 - val_accuracy: 0.9080\n",
            "Epoch 2/2\n",
            "1250/1250 [==============================] - 1881s 2s/step - loss: 0.0905 - accuracy: 0.9708 - val_loss: 0.3205 - val_accuracy: 0.9100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55551618d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRyxax-4MSC4"
      },
      "source": [
        "## **Q3(d)Traditional ML models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m9wW57MJTEL"
      },
      "source": [
        "###**(i)Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6kB1y4rB8U3"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIw1dd2BE4B3"
      },
      "source": [
        "**Naive bayes Using TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQhyEskiFKTS"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(X_tfidf,bin_sentiment,random_state=40)\n",
        "print(X_test.shape)\n",
        "print(X_test[:,1].shape)\n",
        "clf1=naive_bayes.MultinomialNB()\n",
        "clf1.fit(X_train,Y_train)\n",
        "yp=clf1.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InLAqV124YVt"
      },
      "source": [
        "**Naive Bayes Using Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCLMzL-o0Jz4"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(abs(embedding_matrix[:25000]),bin_sentiment,random_state=40)  #embed:64615x100... bin_senti: 25000,1\n",
        "print(X_test.shape)\n",
        "print(X_test[:,1].shape)\n",
        "clf1=naive_bayes.MultinomialNB()\n",
        "clf1.fit(X_train,Y_train)\n",
        "yp=clf1.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyCYsESONeBV"
      },
      "source": [
        "**Naive Bayes using Glove embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnANty5uLJAM"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(abs(embedding_matrix_glove[:25000]),bin_sentiment,random_state=40)  #embed:64615x100... bin_senti: 25000,1\n",
        "print(X_test.shape)\n",
        "print(X_test[:,1].shape)\n",
        "clf1=naive_bayes.MultinomialNB()\n",
        "clf1.fit(X_train,Y_train)\n",
        "yp=clf1.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhavunxeV_-K"
      },
      "source": [
        "###**(ii)Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO7hjpdNXFYb"
      },
      "source": [
        "from sklearn import tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4j4nGapFLGC"
      },
      "source": [
        "**Decision Tree Using TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TseVA942V_CN"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(X_tfidf,bin_sentiment,random_state=40) #25% test data and 75% train data\n",
        "\n",
        "clf3=tree.DecisionTreeClassifier()\n",
        "clf3.fit(X_train,Y_train)\n",
        "yp=clf3.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmI1Pfb2bcaq"
      },
      "source": [
        "**Decision Tree with Word2Vec Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj7s8tzzandH"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(abs(embedding_matrix[:25000]),bin_sentiment,random_state=40) #25% test data and 75% train data\n",
        "\n",
        "clf3=tree.DecisionTreeClassifier()\n",
        "clf3.fit(X_train,Y_train)\n",
        "yp=clf3.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuPiWwgkbhv2"
      },
      "source": [
        "**Decision Tree With Glove embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK_X3GALazRy"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(abs(embedding_matrix_glove[:25000]),bin_sentiment,random_state=40) #25% test data and 75% train data\n",
        "\n",
        "clf3=tree.DecisionTreeClassifier()\n",
        "clf3.fit(X_train,Y_train)\n",
        "yp=clf3.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsFDuY6v9YCW"
      },
      "source": [
        "### **(iii)Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYjWpFp-9Xhj"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz2Cp-BmFDbn"
      },
      "source": [
        "**Logistic Regression Using TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaglN3J8VjD7"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(X_tfidf,bin_sentiment,random_state=40)\n",
        "print(X_test.shape)\n",
        "print(X_test[:,1].shape)\n",
        "clf2=LogisticRegression()\n",
        "clf2.fit(X_train,Y_train)\n",
        "yp=clf2.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4P2BG2Obk1j"
      },
      "source": [
        "**Logisitic Regression Using Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXXWZlgn5HwQ"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(abs(embedding_matrix[:25000]),bin_sentiment,random_state=40)\n",
        "print(X_test.shape)\n",
        "print(X_test[:,1].shape)\n",
        "clf2=LogisticRegression()\n",
        "clf2.fit(X_train,Y_train)\n",
        "yp=clf2.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0rzjN-wboGe"
      },
      "source": [
        "**Logistic Regression Using Glove embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "affOOI7N5Hzf"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(abs(embedding_matrix_glove[:25000]),bin_sentiment,random_state=40)\n",
        "print(X_test.shape)\n",
        "print(X_test[:,1].shape)\n",
        "clf2=LogisticRegression()\n",
        "clf2.fit(X_train,Y_train)\n",
        "yp=clf2.predict(X_test)\n",
        "print(Y_test)\n",
        "print(yp)\n",
        "print(accuracy_score(Y_test,yp))\n",
        "print(f1_score(Y_test,yp))\n",
        "print(confusion_matrix(Y_test,yp))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}