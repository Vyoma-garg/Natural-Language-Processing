{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch_Text_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xX_vH87mvvCMYxJoWJtUGA-pvPkbMmj_",
      "authorship_tag": "ABX9TyNLreAqUCbCkR33Yq6Hdcsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vyoma-garg/Natural-Language-Processing/blob/main/Torch_Text_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "ch50N_k0YZfx",
        "outputId": "46bd2292-7677-4f98-ff0c-cb66e2ae96ae"
      },
      "source": [
        "!pip install -U torchtext==0.8.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed torchtext-0.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eLs2DsEX953"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "\n",
        "#from torchtext.legacy import data "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4KRrd8RYCF3",
        "outputId": "aeb94850-0868-4bd5-a78d-bbb788dfd9fc"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc03iEjQX2KB",
        "outputId": "9a3d375e-ed62-4a09-fc00-7850d1f87e3b"
      },
      "source": [
        "######### Loading from JSON/CSV/TSV files #########\n",
        "\n",
        "# STEPS:\n",
        "# 1. Specify how preprocessing should be done -> Fields\n",
        "# 2. Use Dataset to load the data -> TabularDataset (JSON/CSV/TSV Files)\n",
        "# 3. Construct an iterator to do batching & padding -> BucketIterator\n",
        "\n",
        "\n",
        "!pip install spacy \n",
        "!python -m spacy download en\n",
        "spacy_en = spacy.load(\"en\")\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "#tokenize=lambda x : x.split()\n",
        "\n",
        "quote = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True)\n",
        "score = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "fields = {\"quote\": (\"q\", quote), \"score\": (\"s\", score)}\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(\n",
        "    path=\"/content/drive/MyDrive/Custom_Text_dataset\", train=\"train.json\", test=\"test.json\", format=\"json\", fields=fields\n",
        ")\n",
        "\n",
        "# # train_data, test_data = TabularDataset.splits(\n",
        "# #                                         path='mydata',\n",
        "# #                                         train='train.csv',\n",
        "# #                                         test='test.csv',\n",
        "# #                                         format='csv',\n",
        "# #                                         fields=fields)\n",
        "\n",
        "# # train_data, test_data = TabularDataset.splits(\n",
        "# #                                         path='mydata',\n",
        "# #                                         train='train.tsv',\n",
        "# #                                         test='test.tsv',\n",
        "# #                                         format='tsv',\n",
        "# #                                         fields=fields)\n",
        "\n",
        "print(train_data[0].__dict__.keys())\n",
        "print(train_data[0].__dict__.values())\n",
        "print(train_data[1].__dict__.values())\n",
        "print(train_data[2].__dict__.values())\n",
        "\n",
        "quote.build_vocab(train_data, max_size=10000, min_freq=1, \n",
        "                  vectors=\"glove.6B.100d\"\n",
        "                  )\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data), batch_size=2, device=device\n",
        ")\n",
        "\n",
        "for batch in train_iterator:\n",
        "  print(batch.q)  #torch text pads the sequences itself where there is no token as 1\n",
        "  print(batch.s)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.1.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
            ".vector_cache/glove.6B.zip:   0%|          | 8.19k/862M [00:00<5:00:21, 47.8kB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['q', 's'])\n",
            "dict_values([['you', 'must', 'own', 'everything', 'in', 'your', 'world', '.', 'there', 'is', 'no', 'one', 'else', 'to', 'blame', '.'], 1])\n",
            "dict_values([['do', 'not', 'pray', 'for', 'an', 'easy', 'life', ',', 'pray', 'for', 'the', 'strength', 'to', 'endure', 'a', 'difficult', 'one', '.'], 1])\n",
            "dict_values([['stand', 'tall', ',', 'and', 'rice', 'like', 'a', 'potato', '!'], 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.39MB/s]                           \n",
            " 99%|█████████▉| 397748/400000 [00:17<00:00, 27263.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[35],\n",
            "        [23],\n",
            "        [26],\n",
            "        [18],\n",
            "        [19],\n",
            "        [36],\n",
            "        [34],\n",
            "        [ 2],\n",
            "        [33],\n",
            "        [20],\n",
            "        [24],\n",
            "        [ 6],\n",
            "        [16],\n",
            "        [ 8],\n",
            "        [12],\n",
            "        [ 2]])\n",
            "tensor([1])\n",
            "tensor([[29, 14],\n",
            "        [31, 25],\n",
            "        [ 3,  7],\n",
            "        [11,  5],\n",
            "        [28, 10],\n",
            "        [22, 15],\n",
            "        [ 4, 21],\n",
            "        [27,  3],\n",
            "        [ 9,  7],\n",
            "        [ 1,  5],\n",
            "        [ 1, 32],\n",
            "        [ 1, 30],\n",
            "        [ 1,  8],\n",
            "        [ 1, 17],\n",
            "        [ 1,  4],\n",
            "        [ 1, 13],\n",
            "        [ 1,  6],\n",
            "        [ 1,  2]])\n",
            "tensor([0, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIm2d1Deg3Ip"
      },
      "source": [
        "######### Training a simple LSTM on this toy data of ours #########\n",
        "class RNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n",
        "        super(RNN_LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers)\n",
        "        self.fc_out = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "        outputs, _ = self.rnn(embedded, (h0, c0))\n",
        "        prediction = self.fc_out(outputs[-1, :, :])\n",
        "\n",
        "        return prediction"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBSSj2Gkhm8D",
        "outputId": "ea65ad65-e421-4a24-fcf1-672732ccb9d8"
      },
      "source": [
        " len(quote.vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEUJ-vLTg8UW"
      },
      "source": [
        "# Hyperparameters\n",
        "input_size = len(quote.vocab)\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "embedding_size = 100\n",
        "learning_rate = 0.005\n",
        "num_epochs = 10"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rAvYqgChBv_"
      },
      "source": [
        "# Initialize network\n",
        "model = RNN_LSTM(input_size, embedding_size, hidden_size, num_layers).to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au1Q29aphEj_",
        "outputId": "fab5a276-ef47-4bb3-8e1a-d795a7ff2ec2"
      },
      "source": [
        "# (NOT COVERED IN YOUTUBE VIDEO): Load the pretrained embeddings onto our model\n",
        "pretrained_embeddings = quote.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "print(pretrained_embeddings.shape)\n",
        "print(pretrained_embeddings)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([37, 100])\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
            "        ...,\n",
            "        [ 0.4918,  1.1164,  1.1424,  ..., -0.5088,  0.6256,  0.4392],\n",
            "        [-0.4989,  0.7660,  0.8975,  ..., -0.4118,  0.4054,  0.7850],\n",
            "        [-0.5718,  0.0463,  0.8673,  ..., -0.3566,  0.9293,  0.8995]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftMRRNrPhF2p"
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2duRaQyvhJDU",
        "outputId": "8bcef52f-0f96-4859-d70f-2c1cce1c52dc"
      },
      "source": [
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    losses=[]\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get data to cuda if possible\n",
        "        data = batch.q.to(device=device)\n",
        "        targets = batch.s.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        #print(scores.shape)\n",
        "        loss = criterion(scores.squeeze(1), targets.type_as(scores))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent\n",
        "        optimizer.step()\n",
        "    print(f\"Loss at epoch {epoch} is { sum(losses)/len(losses) :.5f}\") "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 is 0.55137\n",
            "Loss at epoch 1 is 0.48148\n",
            "Loss at epoch 2 is 0.36660\n",
            "Loss at epoch 3 is 0.23677\n",
            "Loss at epoch 4 is 0.11191\n",
            "Loss at epoch 5 is 0.04681\n",
            "Loss at epoch 6 is 2.41923\n",
            "Loss at epoch 7 is 1.75828\n",
            "Loss at epoch 8 is 0.83441\n",
            "Loss at epoch 9 is 0.20301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbD5uw7ukLlE",
        "outputId": "f057bc24-5816-4c0f-a689-400106709119"
      },
      "source": [
        "def check_accuracy(loader,model):\n",
        "  if loader.dataset.train:\n",
        "        print('Checking Accuracy on Training Data')\n",
        "  else:\n",
        "        print('Checking Accuracy on Test Data')\n",
        "  num_correct=0\n",
        "  num_samples=0\n",
        "  model.eval()\n",
        "\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "      x = batch.q.to(device=device)\n",
        "      y = batch.s.to(device=device)\n",
        "    \n",
        "      scores=model(x)  \n",
        "      values,predictions =scores.max(1)  #interested in index of the max value\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_samples += predictions.size(0) \n",
        "\n",
        "  print(f'Got {num_correct}/ {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f} \\n')\n",
        "\n",
        "  model.train()\n",
        "\n",
        "check_accuracy(train_iterator, model)\n",
        "check_accuracy(test_iterator, model)\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking Accuracy on Training Data\n",
            "Got 1/ 3 with accuracy 33.33 \n",
            "\n",
            "Checking Accuracy on Training Data\n",
            "Got 1/ 3 with accuracy 33.33 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
