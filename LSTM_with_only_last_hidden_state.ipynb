{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_with_only_last_hidden_state.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2CF3osIKcgqKSu01GfkRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vyoma-garg/Natural-Language-Processing/blob/main/LSTM_with_only_last_hidden_state.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PawkenIL-laD"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn  #all the NN network, CNN, Modules, loss functions, activation fns\n",
        "import torch.optim as optim  #SGD, ADAM\n",
        "import torch.nn.functional as F  #activation fn, \n",
        "from torch.utils.data import DataLoader  #easier data managemnet, creates mini batches of the data\n",
        "import torchvision.datasets as datasets   #standard datasets MNISt ,etc\n",
        "import torchvision.transforms as transforms  # transformations "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQRdYjItwXxA"
      },
      "source": [
        "Create LSTM with only last hidden state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCNeN_033SLl"
      },
      "source": [
        "class LSTM(nn.Module): #inherit from nn.Module class\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM,self).__init__()   \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm= nn.LSTM(input_size, hidden_size, num_layers, batch_first=True )\n",
        "        #returns batch_size x seq x features --> 64x28x28\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size,num_classes)  #for each hidden state\n",
        "\n",
        "    def forward(self, x): \n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "         # init as num of layers, size: how many min batches we need to send in \n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "         #forward \n",
        "        out,_ = self.lstm(x, (h0,c0))\n",
        "        #out=out.reshape(out.shape[0],-1)  #28x256\n",
        "        #for only last hidden state\n",
        "        out = self.fc(out[:,-1,:])  #all batches at a same time, last hidden state,all features\n",
        "        return out\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1RsRNTmwhDe"
      },
      "source": [
        "Checking "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tjNXA7Wo7Jn"
      },
      "source": [
        "#model = CNN()\n",
        "#x = torch.randn(64,1,28,28)  #randomly generated data, batch size=4, number of examples used simultaneously\n",
        "#print(x)\n",
        "#print('\\n',model(x).shape,'\\n')  #64x10   \n",
        "#print(model(x)) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqfHDi2FoP58"
      },
      "source": [
        "Setting device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm5Lamd6nVNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1d4eba-6841-471c-ddc9-d0cab71711b2"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfxgXlJGoNHv"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XahNlbbwnCor"
      },
      "source": [
        "input_size=28  #28 times seq, each seq have 28 features\n",
        "sequence_length=28  #each row at time stamp\n",
        "num_layers=2\n",
        "hidden_size=256\n",
        "num_classes=10\n",
        "learning_rate=0.001\n",
        "batch_size=64\n",
        "num_epochs=1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8mvvCsMoGyO"
      },
      "source": [
        "Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA1BewQJnwrN"
      },
      "source": [
        "train_dataset = datasets.MNIST(root = '/content', train = True , transform = transforms.ToTensor(), download = True)\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataset = datasets.MNIST(root = '/content', train = False , transform = transforms.ToTensor(), download = True)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcwXlrLboY3E"
      },
      "source": [
        "Initialize network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-57JiV3PoYJ5"
      },
      "source": [
        "model=LSTM(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dknhMuqKolO2"
      },
      "source": [
        "Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyqlZM30oksL"
      },
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jkbybF0pFz-"
      },
      "source": [
        "Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5147I3lpFTq"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data,targets) in enumerate(train_loader):  #enumerate helps in getting the batch index of the data \n",
        "     #Get data to cuda\n",
        "      data = data.to(device).squeeze(1)  #([64,1,28,28])  --> ([64,28,28])\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      #print(data.shape)  #([64,1,28,28])  num of examples, number of channels(black white img), height width of each image\n",
        "                        \n",
        "      #get correct shape\n",
        "      #data=data.reshape(data.shape[0],-1)  #flatten to single dim: ([64,784])\n",
        "      #print(data.shape) \n",
        "\n",
        "      #forward\n",
        "      scores=model(data)\n",
        "      loss=criterion(scores, targets) \n",
        "\n",
        "      #backward\n",
        "      optimizer.zero_grad() #\n",
        "      loss.backward()\n",
        "\n",
        "      #gradient descent or adam step\n",
        "      optimizer.step() #update weights based on the gradients\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e38wBZ8ltU-H"
      },
      "source": [
        "Check accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJRYLHGZtWgb",
        "outputId": "253b961e-aae3-4da1-fdc4-cd5df1ec6d72"
      },
      "source": [
        "def check_accuracy(loader,model):\n",
        "  if loader.dataset.train:\n",
        "        print('Checking Accuracy on Training Data')\n",
        "  else:\n",
        "        print('Checking Accuracy on Test Data')\n",
        "  num_correct=0\n",
        "  num_samples=0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():  #while checking accuracy no need to calculate the gradients again\n",
        "    for x,y in loader:\n",
        "      x=x.to(device=device).squeeze(1)\n",
        "      y=y.to(device=device)\n",
        "      #x=x.reshape(x.shape[0],-1)\n",
        "\n",
        "      scores=model(x)  #64x10 shape of the scores, which is max of those 10 digits\n",
        "      values,predictions =scores.max(1)  #interested in index of the max value\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_samples += predictions.size(0)  #first dimension that is 64 x 10==64\n",
        "    print(f'Got {num_correct}/ {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f} \\n')\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "\n",
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking Accuracy on Training Data\n",
            "Got 57808/ 60000 with accuracy 96.35 \n",
            "\n",
            "Checking Accuracy on Test Data\n",
            "Got 9628/ 10000 with accuracy 96.28 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}